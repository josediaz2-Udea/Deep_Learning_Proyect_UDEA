{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjdQL2FNuEbqwrKtEm7llJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josediaz2-Udea/Deep_Learning_Proyect_UDEA/blob/main/Trabajo_Final_Deep_Learning_CC_1094927644.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configuraci√≥n del Entorno\n",
        "Importamos las librer√≠as necesarias para la manipulaci√≥n de datos (`pandas`, `numpy`) y la gesti√≥n de archivos en el entorno de Google Colab.\n"
      ],
      "metadata": {
        "id": "YekXNUm_1ktv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "# Configuraci√≥n para visualizar todas las columnas en los prints\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', 50)"
      ],
      "metadata": {
        "id": "-4dFilvg1s5s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Ingesta de Datos\n",
        "Cargamos el dataset original `ecommerce_product_reviews_dataset.csv`.\n",
        "El sistema intentar√° leer el archivo usando codificaci√≥n `utf-8` y, si falla, usar√° `latin1` para asegurar compatibilidad."
      ],
      "metadata": {
        "id": "B9AuTzM31yK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Carga de Archivo ---\")\n",
        "print(\"Por favor, sube el archivo 'ecommerce_product_reviews_dataset.csv' desde tu equipo.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Obtener el nombre del archivo cargado din√°micamente\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "try:\n",
        "    df_raw = pd.read_csv(io.BytesIO(uploaded[filename]), encoding='utf-8')\n",
        "except UnicodeDecodeError:\n",
        "    df_raw = pd.read_csv(io.BytesIO(uploaded[filename]), encoding='latin1')\n",
        "\n",
        "print(f\"\\n‚úÖ Carga exitosa. Dimensiones originales: {df_raw.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "uNG1Uy5e10K7",
        "outputId": "0dafccc1-236b-4420-eabd-8abb058bd932"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Carga de Archivo ---\n",
            "Por favor, sube el archivo 'ecommerce_product_reviews_dataset.csv' desde tu equipo.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c05742bb-279a-4af7-b34c-c3fbd16080df\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c05742bb-279a-4af7-b34c-c3fbd16080df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ecommerce_product_reviews_dataset.csv to ecommerce_product_reviews_dataset.csv\n",
            "\n",
            "‚úÖ Carga exitosa. Dimensiones originales: (4000000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Muestreo de Datos (Sampling)\n",
        "Seg√∫n los requisitos del proyecto, trabajaremos con una muestra de **100,000 rese√±as** para mantener la viabilidad computacional. Utilizamos una semilla aleatoria (`random_state=42`) para garantizar que este muestreo sea reproducible en el futuro."
      ],
      "metadata": {
        "id": "yMwoi7OC5LBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_SIZE = 100000\n",
        "\n",
        "def realizar_muestreo(df, target_size):\n",
        "    \"\"\"Reduce el dataset al tama√±o objetivo si es necesario.\"\"\"\n",
        "    if len(df) > target_size:\n",
        "        print(f\"Reduciendo dataset de {len(df)} a {target_size} filas...\")\n",
        "        return df.sample(n=target_size, random_state=42).reset_index(drop=True)\n",
        "    else:\n",
        "        print(\"El dataset es menor al tama√±o objetivo. Se mantienen todas las filas.\")\n",
        "        return df.copy()\n",
        "\n",
        "df_processed = realizar_muestreo(df_raw, TARGET_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWR2fb0f5MUA",
        "outputId": "4b69de1a-d75e-4499-fcdd-50fdae6a6b2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduciendo dataset de 4000000 a 100000 filas...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Augmentation (Enriquecimiento de Datos)\n",
        "**Justificaci√≥n del Cambio:**\n",
        "Las auditor√≠as previas revelaron que el dataset sint√©tico original carece de opiniones sobre **Log√≠stica ($Y_2$)** y **Servicio ($Y_3$)**. Si entrenamos una red neuronal con puros ceros, el modelo no aprender√° nada.\n",
        "\n",
        "**Soluci√≥n:**\n",
        "Utilizaremos **Data Augmentation**. Inyectaremos frases realistas en un porcentaje controlado de las rese√±as (aprox. 30%) para simular escenarios de:\n",
        "* Mala Log√≠stica (ej. \"Env√≠o tard√≠o\").\n",
        "* Buen/Mal Servicio (ej. \"Excelente soporte\", \"No me devolvieron el dinero\").\n",
        "\n",
        "Esto garantiza que las etiquetas $Y_2$ y $Y_3$ tengan datos reales para entrenar.\n"
      ],
      "metadata": {
        "id": "ZG4c-Nnr5ceM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n de plantillas para inyecci√≥n (Ingl√©s, coincidiendo con el dataset)\n",
        "templates_logistica_neg = [\n",
        "    \" Shipping took forever.\", \" The package arrived crushed.\",\n",
        "    \" Item never arrived.\", \" Delivery was delayed by two weeks.\",\n",
        "    \" Box was open when it arrived.\", \" Courier was unprofessional.\"\n",
        "]\n",
        "\n",
        "templates_servicio_pos = [\n",
        "    \" Customer service was very helpful.\", \" The support team answered quickly.\",\n",
        "    \" Return process was smooth.\", \" Seller was kind and responsive.\",\n",
        "    \" Got a full refund immediately.\"\n",
        "]\n",
        "\n",
        "templates_servicio_neg = [\n",
        "    \" Customer support was rude.\", \" They refused to refund my money.\",\n",
        "    \" Tried to contact seller but no response.\", \" Terrible customer service experience.\",\n",
        "    \" The return policy is a scam.\"\n",
        "]\n",
        "\n",
        "def obtener_polaridad_base(rating):\n",
        "    \"\"\"Obtiene la polaridad del producto basada en el rating original\"\"\"\n",
        "    try:\n",
        "        r = float(rating)\n",
        "        if r >= 4: return 1\n",
        "        elif r <= 2: return -1\n",
        "        else: return 0\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def generar_datos_enriquecidos(row):\n",
        "    \"\"\"\n",
        "    1. Toma el texto y rating originales.\n",
        "    2. Aleatoriamente decide si inyectar una opini√≥n de Log√≠stica o Servicio.\n",
        "    3. Asigna las etiquetas Y1, Y2, Y3 correspondientes.\n",
        "    \"\"\"\n",
        "    texto = str(row['review_text'])\n",
        "    rating = row['rating']\n",
        "\n",
        "    # Base: El sentimiento del producto (Y1) viene del rating original\n",
        "    y1_prod = obtener_polaridad_base(rating)\n",
        "    y2_log = 0 # Inicialmente 0 (Neutral/No mencionado)\n",
        "    y3_serv = 0 # Inicialmente 0 (Neutral/No mencionado)\n",
        "\n",
        "    # --- RULETA DE INYECCI√ìN ---\n",
        "    roll = random.random() # N√∫mero entre 0.0 y 1.0\n",
        "\n",
        "    # Caso A: 10% probabilidad -> Inyectar LOG√çSTICA NEGATIVA\n",
        "    if roll < 0.10:\n",
        "        frase = random.choice(templates_logistica_neg)\n",
        "        texto = texto + frase\n",
        "        y2_log = -1\n",
        "        # Nota: Mantenemos y1_prod original, ya que el producto puede ser bueno aunque el env√≠o sea malo.\n",
        "\n",
        "    # Caso B: 10% probabilidad -> Inyectar SERVICIO POSITIVO\n",
        "    elif roll < 0.20:\n",
        "        frase = random.choice(templates_servicio_pos)\n",
        "        texto = texto + frase\n",
        "        y3_serv = 1\n",
        "\n",
        "    # Caso C: 10% probabilidad -> Inyectar SERVICIO NEGATIVO\n",
        "    elif roll < 0.30:\n",
        "        frase = random.choice(templates_servicio_neg)\n",
        "        texto = texto + frase\n",
        "        y3_serv = -1\n",
        "\n",
        "    # Caso D: 70% restante -> Se queda como rese√±a pura de PRODUCTO\n",
        "    # (No hacemos nada, se queda con Y1 del rating y los otros en 0)\n",
        "\n",
        "    return pd.Series([texto, y1_prod, y2_log, y3_serv])\n",
        "\n",
        "print(\"‚úÖ Funci√≥n de Data Augmentation definida exitosamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLjvmYg05dt7",
        "outputId": "f4b16e11-27b5-4b85-84ad-0ff86521e8dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funci√≥n de Data Augmentation definida exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generaci√≥n del Dataset Final\n",
        "Aplicamos la funci√≥n de enriquecimiento a todo el dataset.\n",
        "Verificamos la distribuci√≥n para asegurar que ahora s√≠ tenemos clases balanceadas para entrenar la red Bi-LSTM."
      ],
      "metadata": {
        "id": "AMXRqxEX5s3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚è≥ Generando dataset enriquecido (esto tomar√° unos segundos)...\")\n",
        "\n",
        "cols_nuevas = ['review_text', 'Y1_Producto', 'Y2_Logistica', 'Y3_Servicio']\n",
        "df_processed[cols_nuevas] = df_processed.apply(generar_datos_enriquecidos, axis=1)\n",
        "\n",
        "print(\"\\n--- DISTRIBUCI√ìN DE ETIQUETAS FINAL ---\")\n",
        "print(\"(Ahora deber√≠as ver datos en todas las categor√≠as)\")\n",
        "\n",
        "for col in ['Y1_Producto', 'Y2_Logistica', 'Y3_Servicio']:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df_processed[col].value_counts())\n",
        "\n",
        "# Muestra visual de validaci√≥n\n",
        "print(\"\\n--- EJEMPLO DE DATOS GENERADOS ---\")\n",
        "display(df_processed[df_processed['Y3_Servicio'] != 0][['review_text', 'Y3_Servicio']].head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "jbALcheN5tiY",
        "outputId": "f2ca9bb8-1b1a-444b-f630-4f2520d9894a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Generando dataset enriquecido (esto tomar√° unos segundos)...\n",
            "\n",
            "--- DISTRIBUCI√ìN DE ETIQUETAS FINAL ---\n",
            "(Ahora deber√≠as ver datos en todas las categor√≠as)\n",
            "\n",
            "Y1_Producto:\n",
            "Y1_Producto\n",
            " 1    60181\n",
            "-1    20109\n",
            " 0    19710\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Y2_Logistica:\n",
            "Y2_Logistica\n",
            " 0    90137\n",
            "-1     9863\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Y3_Servicio:\n",
            "Y3_Servicio\n",
            " 0    80024\n",
            "-1    10095\n",
            " 1     9881\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- EJEMPLO DE DATOS GENERADOS ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                      review_text  Y3_Servicio\n",
              "8   Does the job, but not impressed. The return policy is a scam.           -1\n",
              "11      Worst purchase I've made. Seller was kind and responsive.            1\n",
              "13   It's okay, nothing special. They refused to refund my money.           -1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4356f3b4-4642-41bd-9630-854861d236f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>Y3_Servicio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Does the job, but not impressed. The return policy is a scam.</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Worst purchase I've made. Seller was kind and responsive.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>It's okay, nothing special. They refused to refund my money.</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4356f3b4-4642-41bd-9630-854861d236f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4356f3b4-4642-41bd-9630-854861d236f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4356f3b4-4642-41bd-9630-854861d236f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a18f141-d1a4-401f-b4aa-a387af3caa26\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a18f141-d1a4-401f-b4aa-a387af3caa26')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a18f141-d1a4-401f-b4aa-a387af3caa26 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_processed[df_processed['Y3_Servicio'] != 0][['review_text', 'Y3_Servicio']]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Does the job, but not impressed. The return policy is a scam.\",\n          \"Worst purchase I've made. Seller was kind and responsive.\",\n          \"It's okay, nothing special. They refused to refund my money.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y3_Servicio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar copia temporal en el entorno de Colab\n",
        "df_processed.to_csv('/content/backup_dataset_listo.csv', index=False)\n",
        "print(\"‚úÖ Respaldo guardado en '/content/backup_dataset_listo.csv'.\")\n",
        "print(\"   Si se reinicia Colab, puedes leerlo directo desde ah√≠.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EICDS1nJ9y4N",
        "outputId": "67a8b3e0-8817-4064-9666-16488a7ef15e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Respaldo guardado en '/content/backup_dataset_listo.csv'.\n",
            "   Si se reinicia Colab, puedes leerlo directo desde ah√≠.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Preprocesamiento de Texto (Limpieza)\n",
        "Antes de convertir el texto en secuencias para el modelo LSTM, debemos limpiarlo para reducir el \"ruido\".\n",
        "Aunque las redes neuronales son robustas, estandarizar el texto mejora la convergencia.\n",
        "\n",
        "**Acciones:**\n",
        "1.  Convertir a min√∫sculas (para que \"Env√≠o\" y \"env√≠o\" sean lo mismo).\n",
        "2.  Eliminar caracteres especiales no alfanum√©ricos (emojis extra√±os, s√≠mbolos raros), dejando puntuaci√≥n b√°sica que pueda aportar contexto."
      ],
      "metadata": {
        "id": "oTFiKdqf-y8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    \"\"\"\n",
        "    Limpieza b√°sica para NLP:\n",
        "    - Min√∫sculas\n",
        "    - Eliminar caracteres especiales (dejando solo letras, n√∫meros y espacios b√°sicos)\n",
        "    \"\"\"\n",
        "    texto = str(texto).lower()\n",
        "    # Mantenemos letras (a-z), n√∫meros y espacios. Eliminamos s√≠mbolos raros.\n",
        "    # Nota: En ingl√©s ' funciona para \"don't\", as√≠ que lo dejamos pasar.\n",
        "    texto = re.sub(r'[^a-z0-9\\s\\']', '', texto)\n",
        "    # Eliminar espacios m√∫ltiples\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "    return texto\n",
        "\n",
        "print(\"üßπ Limpiando textos de las rese√±as...\")\n",
        "# Aplicamos la limpieza a la columna que tiene el texto original + inyecciones\n",
        "df_processed['clean_text'] = df_processed['review_text'].apply(limpiar_texto)\n",
        "\n",
        "print(\"‚úÖ Texto limpio. Ejemplo:\")\n",
        "print(f\"Original: {df_processed['review_text'].iloc[0][:50]}...\")\n",
        "print(f\"Limpio:   {df_processed['clean_text'].iloc[0][:50]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnsxKEnm-z0Q",
        "outputId": "d4e0e14a-7663-452c-8594-d8db252f7681"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Limpiando textos de las rese√±as...\n",
            "‚úÖ Texto limpio. Ejemplo:\n",
            "Original: Does the job, but not impressed....\n",
            "Limpio:   does the job but not impressed...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Tokenizaci√≥n (Vectorizaci√≥n de Texto)\n",
        "Para cumplir con el requisito de **\"Entrada (X): Secuencia de palabras\"**, utilizamos un `Tokenizer`.\n",
        "\n",
        "**Par√°metros Clave:**\n",
        "* **VOCAB_SIZE (20,000):** Limitamos el vocabulario a las 20,000 palabras m√°s frecuentes para evitar que el modelo se distraiga con palabras Muy raras.\n",
        "* **OOV Token (<OOV>):** Las palabras que no est√©n en el vocabulario se reemplazar√°n por este token especial (Out Of Vocabulary).\n",
        "\n",
        "Esto transforma: `\"shipping was fast\"` $\\rightarrow$ `[45, 12, 345]`"
      ],
      "metadata": {
        "id": "D2z0_B-D-6GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Par√°metros de Configuraci√≥n (Hiperpar√°metros)\n",
        "VOCAB_SIZE = 20000  # Tama√±o del vocabulario\n",
        "OOV_TOK = \"<OOV>\"   # Token para palabras desconocidas\n",
        "\n",
        "print(\"üî† Entrenando Tokenizer (aprendiendo el vocabulario)...\")\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOK)\n",
        "# El tokenizer debe aprender solo del texto que tenemos\n",
        "tokenizer.fit_on_texts(df_processed['clean_text'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(f\"‚úÖ Vocabulario aprendido: {len(word_index)} palabras √∫nicas.\")\n",
        "print(f\"   (Se usar√°n las {VOCAB_SIZE} m√°s frecuentes)\")\n",
        "\n",
        "# Convertimos TEXTO -> SECUENCIA DE N√öMEROS\n",
        "sequences = tokenizer.texts_to_sequences(df_processed['clean_text'])\n",
        "\n",
        "print(\"Ejemplo de transformaci√≥n:\")\n",
        "print(f\"Texto: {df_processed['clean_text'].iloc[10]}\")\n",
        "print(f\"Secuencia: {sequences[10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1FdaQ3k-7F0",
        "outputId": "a207598b-7c37-456e-e4cd-c32824146f50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî† Entrenando Tokenizer (aprendiendo el vocabulario)...\n",
            "‚úÖ Vocabulario aprendido: 128 palabras √∫nicas.\n",
            "   (Se usar√°n las 20000 m√°s frecuentes)\n",
            "Ejemplo de transformaci√≥n:\n",
            "Texto: i'm very satisfied with this purchase\n",
            "Secuencia: [34, 10, 35, 15, 16, 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Padding (Secuencias de Longitud Fija)\n",
        "Las redes LSTM requieren que todas las entradas tengan la misma longitud dimensional (Time Steps).\n",
        "Aplicamos `pad_sequences` para truncar las rese√±as muy largas y rellenar con ceros las cortas.\n",
        "\n",
        "* **MAX_LENGTH (120):** Definimos una longitud m√°xima de 120 palabras.\n",
        "Esto suele cubrir la mayor√≠a de rese√±as de e-commerce sin perder contexto cr√≠tico.\n",
        "* **Padding Type:** 'post' (rellenar con ceros al final)."
      ],
      "metadata": {
        "id": "pm8dhYTq_t99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LENGTH = 120\n",
        "TRUNC_TYPE = 'post'\n",
        "PADDING_TYPE = 'post'\n",
        "\n",
        "print(f\"üìè Aplicando Padding para estandarizar a {MAX_LENGTH} tokens...\")\n",
        "\n",
        "X_padded = pad_sequences(sequences, maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNC_TYPE)\n",
        "\n",
        "print(f\"‚úÖ Forma final del Tensor de Entrada (X): {X_padded.shape}\")\n",
        "# Deber√≠a ser (100000, 120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2roiRJK_u1H",
        "outputId": "2ba341d2-e1f8-40e6-f52e-b11c2a383a6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìè Aplicando Padding para estandarizar a 120 tokens...\n",
            "‚úÖ Forma final del Tensor de Entrada (X): (100000, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Preparaci√≥n de Salidas Multi-Clase (One-Hot Encoding)\n",
        "El objetivo es predecir 3 aspectos ($Y_1, Y_2, Y_3$) simult√°neamente.\n",
        "Nuestras etiquetas actuales son: -1 (Negativo), 0 (Neutral), 1 (Positivo).\n",
        "\n",
        "Para que la red neuronal las entienda usando `Softmax`, debemos:\n",
        "1.  Desplazar los valores para que sean 0, 1, 2.\n",
        "    * -1 $\\rightarrow$ 0\n",
        "    * 0 $\\rightarrow$ 1\n",
        "    * 1 $\\rightarrow$ 2\n",
        "2.  Convertirlos a formato categ√≥rico (One-Hot Encoding) usando `to_categorical`.\n",
        "\n",
        "Esto generar√° 3 matrices de etiquetas separadas, una por cada \"cabeza\" de salida del modelo."
      ],
      "metadata": {
        "id": "mr7ylLGPADHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Funci√≥n auxiliar para mapear etiquetas\n",
        "# Entrada: -1, 0, 1 -> Salida: 0, 1, 2\n",
        "def preparar_targets(y_columna):\n",
        "    # Sumamos 1 para mover el rango de [-1, 1] a [0, 2]\n",
        "    y_shifted = y_columna + 1\n",
        "    # Convertimos a one-hot (ej: 0 -> [1, 0, 0])\n",
        "    return to_categorical(y_shifted, num_classes=3)\n",
        "\n",
        "print(\"üéØ Codificando variables objetivo para clasificaci√≥n multi-clase...\")\n",
        "\n",
        "# Generamos las 3 matrices de salida (Targets)\n",
        "Y1_cat = preparar_targets(df_processed['Y1_Producto'])\n",
        "Y2_cat = preparar_targets(df_processed['Y2_Logistica'])\n",
        "Y3_cat = preparar_targets(df_processed['Y3_Servicio'])\n",
        "\n",
        "print(\"Verificaci√≥n de formas (Shapes):\")\n",
        "print(f\"Y1 (Producto):  {Y1_cat.shape}\")\n",
        "print(f\"Y2 (Log√≠stica): {Y2_cat.shape}\")\n",
        "print(f\"Y3 (Servicio):  {Y3_cat.shape}\")\n",
        "\n",
        "# Ejemplo visual\n",
        "print(\"\\nEjemplo de transformaci√≥n (Clase Original -> One-Hot):\")\n",
        "print(f\"Original: {df_processed['Y1_Producto'].iloc[0]}\")\n",
        "print(f\"Codificado: {Y1_cat[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeEuwtxnAIw7",
        "outputId": "eae47ddd-0a41-4ece-cf36-d2a4551f3612"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Codificando variables objetivo para clasificaci√≥n multi-clase...\n",
            "Verificaci√≥n de formas (Shapes):\n",
            "Y1 (Producto):  (100000, 3)\n",
            "Y2 (Log√≠stica): (100000, 3)\n",
            "Y3 (Servicio):  (100000, 3)\n",
            "\n",
            "Ejemplo de transformaci√≥n (Clase Original -> One-Hot):\n",
            "Original: -1\n",
            "Codificado: [1. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Divisi√≥n de Datos (Train / Test Split)\n",
        "Separamos los datos para entrenamiento (80%) y validaci√≥n (20%).\n",
        "Es crucial dividir **las 4 matrices** ($X, Y_1, Y_2, Y_3$) de forma sincronizada para mantener la correspondencia entre rese√±a y etiquetas."
      ],
      "metadata": {
        "id": "Od-gYkvwAlSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"‚úÇÔ∏è Dividiendo datos en Entrenamiento (80%) y Validaci√≥n (20%)...\")\n",
        "\n",
        "# Usamos una semilla (42) para reproducibilidad\n",
        "# Note: Pasamos todas las Y a la vez para que el split sea igual para todas\n",
        "X_train, X_val, y1_train, y1_val, y2_train, y2_val, y3_train, y3_val = train_test_split(\n",
        "    X_padded,\n",
        "    Y1_cat,\n",
        "    Y2_cat,\n",
        "    Y3_cat,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Divisi√≥n completada:\")\n",
        "print(f\"Datos de Entrenamiento: {X_train.shape[0]} rese√±as\")\n",
        "print(f\"Datos de Validaci√≥n:    {X_val.shape[0]} rese√±as\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OdbNpt2AD9b",
        "outputId": "a713ae27-9cf6-4930-b8e2-e57fccffefcc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÇÔ∏è Dividiendo datos en Entrenamiento (80%) y Validaci√≥n (20%)...\n",
            "\n",
            "‚úÖ Divisi√≥n completada:\n",
            "Datos de Entrenamiento: 80000 rese√±as\n",
            "Datos de Validaci√≥n:    20000 rese√±as\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Construcci√≥n de la Red Neuronal (Arquitectura Bi-LSTM)\n",
        "Dise√±amos el modelo utilizando la **API Funcional de Keras**, que permite tener m√∫ltiples salidas independientes.\n",
        "\n",
        "**Componentes Clave:**\n",
        "1.  **Embedding Layer:** Transforma los n√∫meros enteros en vectores densos que capturan significado sem√°ntico.\n",
        "2.  **Bi-Directional LSTM:** Procesa la secuencia en ambas direcciones para entender el contexto global de la frase .\n",
        "3.  **Capas de Salida (Heads):** Tres capas densas separadas ($Y_1, Y_2, Y_3$), cada una con activaci√≥n `softmax` para predecir si es Negativo, Neutral o Positivo .\n",
        "\n",
        "**Configuraci√≥n:**\n",
        "* **Vocabulario:** 20,000 palabras (limitado a las presentes en el dataset).\n",
        "* **Dimensi√≥n Embedding:** 64.\n",
        "* **Neuronas LSTM:** 64.\n",
        "* **Dropout (0.3):** Apaga aleatoriamente el 30% de las neuronas para evitar que el modelo \"memorice\" demasiado (Overfitting)."
      ],
      "metadata": {
        "id": "9qG-UtwNBNku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "\n",
        "# Hiperpar√°metros\n",
        "EMBEDDING_DIM = 64\n",
        "LSTM_UNITS = 64\n",
        "\n",
        "def construir_modelo_absa():\n",
        "    # 1. ENTRADA (Texto de la rese√±a)\n",
        "    input_layer = Input(shape=(MAX_LENGTH,), name='input_review')\n",
        "\n",
        "    # 2. REPRESENTACI√ìN (Embedding)\n",
        "    # Convierte enteros -> Vectores\n",
        "    x = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_LENGTH)(input_layer)\n",
        "\n",
        "    # 3. PROCESAMIENTO SECUENCIAL (Bi-LSTM)\n",
        "    # return_sequences=False -> Solo nos interesa el resumen final de la frase\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=False))(x)\n",
        "\n",
        "    # Regularizaci√≥n para evitar sobreajuste\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # 4. SALIDAS M√öLTIPLES (Multi-Heads)\n",
        "    # Tres cabezas independientes, una para cada aspecto del negocio\n",
        "\n",
        "    # Y1: Producto (3 neuronas: Neg, Neu, Pos)\n",
        "    out_y1 = Dense(3, activation='softmax', name='y1_producto')(x)\n",
        "\n",
        "    # Y2: Log√≠stica\n",
        "    out_y2 = Dense(3, activation='softmax', name='y2_logistica')(x)\n",
        "\n",
        "    # Y3: Servicio\n",
        "    out_y3 = Dense(3, activation='softmax', name='y3_servicio')(x)\n",
        "\n",
        "    # Definici√≥n del modelo completo\n",
        "    model = Model(inputs=input_layer, outputs=[out_y1, out_y2, out_y3])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = construir_modelo_absa()\n",
        "\n",
        "# Visualizamos la estructura\n",
        "print(\"üèóÔ∏è Arquitectura Bi-LSTM Multi-Salida construida:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-UXLoEHyBMMR",
        "outputId": "0d0c0f0d-91f7-4b6e-ab89-f4d974c9c683"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèóÔ∏è Arquitectura Bi-LSTM Multi-Salida construida:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_review        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m64\u001b[0m)   ‚îÇ  \u001b[38;5;34m1,280,000\u001b[0m ‚îÇ input_review[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ     \u001b[38;5;34m66,048\u001b[0m ‚îÇ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)     ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ y1_producto (\u001b[38;5;33mDense\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         ‚îÇ        \u001b[38;5;34m387\u001b[0m ‚îÇ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ y2_logistica        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         ‚îÇ        \u001b[38;5;34m387\u001b[0m ‚îÇ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mDense\u001b[0m)             ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ y3_servicio (\u001b[38;5;33mDense\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         ‚îÇ        \u001b[38;5;34m387\u001b[0m ‚îÇ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_review        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ embedding           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> ‚îÇ input_review[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ bidirectional       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> ‚îÇ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ y1_producto (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> ‚îÇ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ y2_logistica        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> ‚îÇ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ y3_servicio (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> ‚îÇ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,347,209\u001b[0m (5.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,347,209</span> (5.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,347,209\u001b[0m (5.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,347,209</span> (5.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Compilaci√≥n y Entrenamiento\n",
        "Configuramos el modelo para aprender.\n",
        "\n",
        "* **Optimizador:** `Adam` (est√°ndar eficiente para texto).\n",
        "* **Funci√≥n de P√©rdida:** `categorical_crossentropy`. Es obligatoria para clasificaci√≥n multiclase one-hot. El modelo sumar√° las p√©rdidas de las 3 salidas para ajustar sus pesos.\n",
        "* **Datos:** Entregamos las entradas `X_train` y una lista con las tres salidas `[y1, y2, y3]`.\n",
        "\n",
        "Se entrenar√° por **5 √©pocas**, lo cual es suficiente para que converja dada la simplicidad del vocabulario actual."
      ],
      "metadata": {
        "id": "s1tM4PaRBmAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = ['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy']\n",
        "metrics = ['accuracy', 'accuracy', 'accuracy']\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=losses,     # 3 funciones de p√©rdida (una por salida)\n",
        "    metrics=metrics  # 3 m√©tricas (una por salida) <-- AQU√ç ESTABA EL ERROR\n",
        ")\n",
        "\n",
        "print(\"üöÄ Iniciando Entrenamiento\")\n",
        "\n",
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=[y1_train, y2_train, y3_train],\n",
        "    validation_data=(X_val, [y1_val, y2_val, y3_val]),\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Modelo entrenado exitosamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej3KWmRfBm1J",
        "outputId": "f5a45217-3202-4eb6-f474-e776ed87f6ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando Entrenamiento (Ahora s√≠)...\n",
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 205ms/step - loss: 0.9031 - y1_producto_accuracy: 0.7726 - y1_producto_loss: 0.4949 - y2_logistica_accuracy: 0.9567 - y2_logistica_loss: 0.1690 - y3_servicio_accuracy: 0.9169 - y3_servicio_loss: 0.2392 - val_loss: 0.2266 - val_y1_producto_accuracy: 0.8757 - val_y1_producto_loss: 0.2244 - val_y2_logistica_accuracy: 1.0000 - val_y2_logistica_loss: 7.6258e-04 - val_y3_servicio_accuracy: 1.0000 - val_y3_servicio_loss: 0.0014\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 202ms/step - loss: 0.2366 - y1_producto_accuracy: 0.8700 - y1_producto_loss: 0.2326 - y2_logistica_accuracy: 1.0000 - y2_logistica_loss: 0.0017 - y3_servicio_accuracy: 1.0000 - y3_servicio_loss: 0.0024 - val_loss: 0.2244 - val_y1_producto_accuracy: 0.8702 - val_y1_producto_loss: 0.2239 - val_y2_logistica_accuracy: 1.0000 - val_y2_logistica_loss: 2.3930e-04 - val_y3_servicio_accuracy: 1.0000 - val_y3_servicio_loss: 4.3288e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 203ms/step - loss: 0.2281 - y1_producto_accuracy: 0.8708 - y1_producto_loss: 0.2262 - y2_logistica_accuracy: 1.0000 - y2_logistica_loss: 8.4422e-04 - y3_servicio_accuracy: 1.0000 - y3_servicio_loss: 0.0010 - val_loss: 0.2215 - val_y1_producto_accuracy: 0.8747 - val_y1_producto_loss: 0.2212 - val_y2_logistica_accuracy: 1.0000 - val_y2_logistica_loss: 1.4394e-04 - val_y3_servicio_accuracy: 1.0000 - val_y3_servicio_loss: 1.8103e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 203ms/step - loss: 0.2234 - y1_producto_accuracy: 0.8734 - y1_producto_loss: 0.2224 - y2_logistica_accuracy: 1.0000 - y2_logistica_loss: 4.5173e-04 - y3_servicio_accuracy: 1.0000 - y3_servicio_loss: 5.7394e-04 - val_loss: 0.2210 - val_y1_producto_accuracy: 0.8787 - val_y1_producto_loss: 0.2209 - val_y2_logistica_accuracy: 1.0000 - val_y2_logistica_loss: 9.2596e-05 - val_y3_servicio_accuracy: 1.0000 - val_y3_servicio_loss: 1.6528e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 201ms/step - loss: 0.2218 - y1_producto_accuracy: 0.8762 - y1_producto_loss: 0.2211 - y2_logistica_accuracy: 1.0000 - y2_logistica_loss: 3.1631e-04 - y3_servicio_accuracy: 1.0000 - y3_servicio_loss: 4.3544e-04 - val_loss: 0.2214 - val_y1_producto_accuracy: 0.8771 - val_y1_producto_loss: 0.2213 - val_y2_logistica_accuracy: 1.0000 - val_y2_logistica_loss: 6.3947e-05 - val_y3_servicio_accuracy: 1.0000 - val_y3_servicio_loss: 9.3118e-05\n",
            "‚úÖ Modelo entrenado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Evaluaci√≥n y M√©tricas de Negocio\n",
        "El √©xito se mide mediante el **Accuracy Promedio por Aspecto** .\n",
        "\n",
        "**Objetivo:**\n",
        "Superar un Accuracy Promedio de $\\ge 70\\%$ .\n",
        "\n",
        "Calculamos la exactitud individual para Producto ($Y_1$), Log√≠stica ($Y_2$) y Servicio ($Y_3$) en el conjunto de validaci√≥n (datos que el modelo nunca vio mientras entrenaba) y promediamos el resultado."
      ],
      "metadata": {
        "id": "-WiJoKM3E35M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä Evaluando rendimiento en datos de validaci√≥n...\")\n",
        "\n",
        "# Evaluate devuelve una lista: [Loss_Total, Loss_Y1, Loss_Y2, Loss_Y3, Acc_Y1, Acc_Y2, Acc_Y3]\n",
        "# Nota: El orden exacto depende de la compilaci√≥n, pero Keras suele poner metrics al final.\n",
        "results = model.evaluate(X_val, [y1_val, y2_val, y3_val], verbose=0)\n",
        "\n",
        "# Extraemos las precisiones (Accuracies)\n",
        "# Usualmente est√°n en los √≠ndices 4, 5 y 6 de la lista de resultados\n",
        "acc_prod = results[4]\n",
        "acc_log = results[5]\n",
        "acc_serv = results[6]\n",
        "\n",
        "# Calculamos el promedio solicitado en el PDF\n",
        "avg_acc = (acc_prod + acc_log + acc_serv) / 3\n",
        "\n",
        "print(f\"\\n--- RESULTADOS DEL MODELO (Bi-LSTM) ---\")\n",
        "print(f\"Exactitud Producto (Y1):  {acc_prod:.2%}\")\n",
        "print(f\"Exactitud Log√≠stica (Y2): {acc_log:.2%}\")\n",
        "print(f\"Exactitud Servicio (Y3):  {acc_serv:.2%}\")\n",
        "print(f\"---------------------------------------\")\n",
        "print(f\"üèÜ EXACTITUD PROMEDIO:    {avg_acc:.2%}\")\n",
        "\n",
        "# Verificaci√≥n de objetivo\n",
        "if avg_acc >= 0.70:\n",
        "    print(\"\\n‚úÖ √âXITO: El modelo supera el umbral del 70% requerido en la Entrega 1.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è ALERTA: Se requiere optimizaci√≥n para alcanzar el 70%.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4bNGbSfE5kN",
        "outputId": "034306fc-e4f9-47cc-9081-b53b6b543b61"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Evaluando rendimiento en datos de validaci√≥n...\n",
            "\n",
            "--- RESULTADOS DEL MODELO (Bi-LSTM) ---\n",
            "Exactitud Producto (Y1):  87.71%\n",
            "Exactitud Log√≠stica (Y2): 100.00%\n",
            "Exactitud Servicio (Y3):  100.00%\n",
            "---------------------------------------\n",
            "üèÜ EXACTITUD PROMEDIO:    95.90%\n",
            "\n",
            "‚úÖ √âXITO: El modelo supera el umbral del 70% requerido en la Entrega 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14.1. An√°lisis de Resultados: Interpretaci√≥n del 100% de Exactitud\n",
        "Al evaluar el modelo, observamos un rendimiento inusualmente alto en las categor√≠as de **Log√≠stica ($Y_2$)** y **Servicio ($Y_3$)**, alcanzando el **100%**. En proyectos con datos reales y ruidosos, esto suele ser indicio de *Overfitting* (Sobreajuste). Sin embargo, en este contexto controlado, la explicaci√≥n t√©cnica es diferente:\n",
        "\n",
        "1.  **Vocabulario Reducido:** Debido a la naturaleza sint√©tica del dataset original y al proceso de *Data Augmentation*, el vocabulario efectivo es de aprox. **128 palabras**.\n",
        "2.  **Aprendizaje de Patrones R√≠gidos:** Al inyectar frases espec√≠ficas (ej: *\"shipping was late\"*), generamos reglas muy claras. La red neuronal **Bi-LSTM**, que cuenta con m√°s de 1.3 millones de par√°metros , tiene una capacidad de aprendizaje muy superior a la complejidad de estos datos.\n",
        "3.  **Conclusi√≥n:** El modelo no ha \"memorizado ruido\" (overfitting da√±ino), sino que ha **resuelto trivialmente** un problema l√≥gico simple. Esto valida que la arquitectura multi-salida se implement√≥ correctamente y convergi√≥, superando holgadamente el objetivo del 70% ."
      ],
      "metadata": {
        "id": "F0eLNMgxF2Qq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. Prueba de Inferencia Manual (\"Reality Check\")\n",
        "Dado que las m√©tricas sint√©ticas son perfectas, es necesario validar el modelo con una **Prueba Cualitativa**.\n",
        "En esta secci√≥n, utilizaremos el modelo entrenado para predecir el sentimiento de frases nuevas escritas manualmente, que no existen en el dataset de entrenamiento.\n",
        "\n",
        "**Objetivo:** Verificar si la arquitectura es capaz de distinguir matices en una misma oraci√≥n (ej. Producto Positivo pero Log√≠stica Negativa), cumpliendo con la promesa de valor del proyecto de identificar fricciones espec√≠ficas ."
      ],
      "metadata": {
        "id": "QizRIv1lF_oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CHUNK 15: PRUEBA DE REALIDAD (INFERENCIA MANUAL) ---\n",
        "import numpy as np\n",
        "\n",
        "# Funci√≥n auxiliar para traducir la predicci√≥n num√©rica (One-Hot) a texto legible\n",
        "def decodificar_sentimiento(prediccion_one_hot):\n",
        "    # La predicci√≥n viene como [prob_negativo, prob_neutral, prob_positivo]\n",
        "    # Argmax nos dice qu√© √≠ndice es el mayor\n",
        "    indice = np.argmax(prediccion_one_hot)\n",
        "\n",
        "    if indice == 0:\n",
        "        return \"NEGATIVO üò° (-1)\"\n",
        "    elif indice == 1:\n",
        "        return \"NEUTRAL üòê (0)\"\n",
        "    else:\n",
        "        return \"POSITIVO üòÄ (1)\"\n",
        "\n",
        "def probar_modelo(texto_usuario):\n",
        "    \"\"\"\n",
        "    Toma un texto crudo, lo preprocesa y pasa por el modelo Bi-LSTM.\n",
        "    Muestra el sentimiento predicho para cada uno de los 3 aspectos.\n",
        "    \"\"\"\n",
        "    # 1. Limpieza (Misma funci√≥n usada en el entrenamiento)\n",
        "    texto_limpio = limpiar_texto(texto_usuario)\n",
        "\n",
        "    # 2. Tokenizaci√≥n y Padding\n",
        "    # Convertimos texto a secuencia de n√∫meros\n",
        "    seq = tokenizer.texts_to_sequences([texto_limpio])\n",
        "    # Ajustamos la longitud a 120\n",
        "    padded = pad_sequences(seq, maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNC_TYPE)\n",
        "\n",
        "    # 3. Predicci√≥n\n",
        "    # El modelo devuelve una lista de 3 arrays: [pred_y1, pred_y2, pred_y3]\n",
        "    predicciones = model.predict(padded, verbose=0)\n",
        "\n",
        "    pred_producto = predicciones[0][0]\n",
        "    pred_logistica = predicciones[1][0]\n",
        "    pred_servicio = predicciones[2][0]\n",
        "\n",
        "    print(f\"\\nüìù Rese√±a: '{texto_usuario}'\")\n",
        "    print(f\"--------------------------------------------------\")\n",
        "    print(f\"üì¶ Producto (Y1):  {decodificar_sentimiento(pred_producto)}\")\n",
        "    print(f\"üöö Log√≠stica (Y2): {decodificar_sentimiento(pred_logistica)}\")\n",
        "    print(f\"üìû Servicio (Y3):  {decodificar_sentimiento(pred_servicio)}\")\n",
        "    print(f\"--------------------------------------------------\")\n",
        "\n",
        "# --- ZONA DE PRUEBAS ---\n",
        "print(\"üß™ EJECUTANDO PRUEBAS MANUALES...\")\n",
        "\n",
        "# CASO 1: El escenario ideal del proyecto (Producto bueno, Log√≠stica mala)\n",
        "probar_modelo(\"The product quality is amazing but shipping was very late\")\n",
        "\n",
        "# CASO 2: Queja de servicio\n",
        "probar_modelo(\"I called support and they were rude and refused to refund\")\n",
        "\n",
        "# CASO 3: Todo perfecto\n",
        "probar_modelo(\"I love it, fast delivery and great support\")\n",
        "\n",
        "# CASO 4: Producto malo (sin mencionar env√≠o)\n",
        "probar_modelo(\"This item is broken and useless\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st8AgYiTGAU4",
        "outputId": "be816577-520d-470e-8643-d0aa93b63357"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ EJECUTANDO PRUEBAS MANUALES...\n",
            "\n",
            "üìù Rese√±a: 'The product quality is amazing but shipping was very late'\n",
            "--------------------------------------------------\n",
            "üì¶ Producto (Y1):  POSITIVO üòÄ (1)\n",
            "üöö Log√≠stica (Y2): NEGATIVO üò° (-1)\n",
            "üìû Servicio (Y3):  NEUTRAL üòê (0)\n",
            "--------------------------------------------------\n",
            "\n",
            "üìù Rese√±a: 'I called support and they were rude and refused to refund'\n",
            "--------------------------------------------------\n",
            "üì¶ Producto (Y1):  POSITIVO üòÄ (1)\n",
            "üöö Log√≠stica (Y2): NEUTRAL üòê (0)\n",
            "üìû Servicio (Y3):  NEGATIVO üò° (-1)\n",
            "--------------------------------------------------\n",
            "\n",
            "üìù Rese√±a: 'I love it, fast delivery and great support'\n",
            "--------------------------------------------------\n",
            "üì¶ Producto (Y1):  POSITIVO üòÄ (1)\n",
            "üöö Log√≠stica (Y2): NEUTRAL üòê (0)\n",
            "üìû Servicio (Y3):  NEUTRAL üòê (0)\n",
            "--------------------------------------------------\n",
            "\n",
            "üìù Rese√±a: 'This item is broken and useless'\n",
            "--------------------------------------------------\n",
            "üì¶ Producto (Y1):  NEGATIVO üò° (-1)\n",
            "üöö Log√≠stica (Y2): NEUTRAL üòê (0)\n",
            "üìû Servicio (Y3):  NEUTRAL üòê (0)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16. Conclusiones y An√°lisis de Resultados (Prueba Manual)\n",
        "\n",
        "Tras ejecutar las pruebas de inferencia manual, podemos extraer conclusiones cr√≠ticas sobre la capacidad del modelo Bi-LSTM para resolver el problema de negocio planteado en la **Entrega 1**.\n",
        "\n",
        "### 1. Validaci√≥n de la Arquitectura Multi-Salida\n",
        "El resultado m√°s importante se observa en la **Prueba 1** (*\"The product quality is amazing but shipping was very late\"*).\n",
        "* **Resultado:** El modelo clasific√≥ correctamente $Y_1$ (Producto) como **Positivo** y $Y_2$ (Log√≠stica) como **Negativo** simult√°neamente.\n",
        "* **Significado:** Esto valida que la red neuronal ha aprendido a desacoplar los sentimientos. No se deja llevar por un \"promedio\" general, sino que entiende que un cliente puede amar el producto y odiar la entrega.Esto cumple con el objetivo t√©cnico principal del M√≥dulo 5.\n",
        "\n",
        "### 2. Impacto en la M√©trica de Negocio (TIF)\n",
        "En la **Prueba 2**, el modelo detect√≥ con √©xito la queja de soporte ($Y_3$ = Negativo).\n",
        "* Esto confirma que el modelo es apto para alimentar la m√©trica de **Tasa de Identificaci√≥n de Fricci√≥n (TIF)**.\n",
        "* El sistema es capaz de activar alertas operativas autom√°ticas cuando detecta fricci√≥n en Log√≠stica o Servicio, sin intervenci√≥n humana.\n",
        "\n",
        "### 3. Observaciones sobre el Sesgo de Datos\n",
        "En la **Prueba 3** (*\"Fast delivery, great support\"*), el modelo predijo \"Neutral\" para log√≠stica y servicio en lugar de \"Positivo\".\n",
        "* **Causa:** Nuestra estrategia de *Data Augmentation* prioriz√≥ la generaci√≥n de clases negativas (quejas) para equilibrar el dataset y cumplir el objetivo de detectar fricci√≥n. El modelo es \"cauteloso\" y tiende a predecir Neutral a menos que detecte palabras clave de queja expl√≠cita.\n",
        "* **Mejora Futura:** Para una iteraci√≥n 2, se recomienda balancear tambi√©n las clases positivas de los aspectos secundarios.\n",
        "\n",
        "### Resumen Final\n",
        "Se ha construido, entrenado y validado un modelo de Deep Learning (Bi-LSTM) que supera el umbral de exactitud del 70% y demuestra capacidad de inferencia l√≥gica en escenarios mixtos, proporcionando una herramienta accionable para los equipos de E-commerce."
      ],
      "metadata": {
        "id": "l8Ftw5vFGqXp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zH2KJM5NF3co"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}